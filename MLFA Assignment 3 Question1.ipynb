{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9571d6d8",
   "metadata": {},
   "source": [
    "# Importing libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc9a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6e81e",
   "metadata": {},
   "source": [
    "# Spliting Training and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e4d77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e85cd7",
   "metadata": {},
   "source": [
    "# Bringing the pixels to a single 1D input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccca06e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e719c7f",
   "metadata": {},
   "source": [
    "# Setting up uniform Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "444b0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((784)),\n",
    "    tf.keras.layers.Dense(50, activation='relu',kernel_initializer=initializer, name='hiddenlayer1'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(93, activation='relu',kernel_initializer=initializer, name='hiddenlayer2'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(93, activation='relu',kernel_initializer=initializer, name='hiddenlayer3'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(93, activation='relu',kernel_initializer=initializer, name='hiddenlayer4'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(93, activation='relu',kernel_initializer=initializer, name='hiddenlayer5'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(93, activation='relu',kernel_initializer=initializer, name='hiddenlayer6'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(93, activation='relu',kernel_initializer=initializer, name='hiddenlayer7'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(93, activation='relu',kernel_initializer=initializer, name='hiddenlayer8'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10,activation='softmax',kernel_initializer=initializer, name='outputlayer')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df8fe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hiddenlayer1 (Dense)        (None, 50)                39250     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 50)               200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " hiddenlayer2 (Dense)        (None, 93)                4743      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 93)               372       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " hiddenlayer3 (Dense)        (None, 93)                8742      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 93)               372       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " hiddenlayer4 (Dense)        (None, 93)                8742      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 93)               372       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " hiddenlayer5 (Dense)        (None, 93)                8742      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 93)               372       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " hiddenlayer6 (Dense)        (None, 93)                8742      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 93)               372       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " hiddenlayer7 (Dense)        (None, 93)                8742      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 93)               372       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " hiddenlayer8 (Dense)        (None, 93)                8742      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 93)               372       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " outputlayer (Dense)         (None, 10)                940       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,189\n",
      "Trainable params: 98,787\n",
      "Non-trainable params: 1,402\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694fcd4c",
   "metadata": {},
   "source": [
    "# Compiling and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8225beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41ff57c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4713 - accuracy: 0.8551\n",
      "Epoch 2/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2370 - accuracy: 0.9292\n",
      "Epoch 3/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1922 - accuracy: 0.9431\n",
      "Epoch 4/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1648 - accuracy: 0.9503\n",
      "Epoch 5/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1426 - accuracy: 0.9572\n",
      "Epoch 6/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1277 - accuracy: 0.9614\n",
      "Epoch 7/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9665\n",
      "Epoch 8/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1044 - accuracy: 0.9680\n",
      "Epoch 9/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0945 - accuracy: 0.9713\n",
      "Epoch 10/35\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0887 - accuracy: 0.9725\n",
      "Epoch 11/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0795 - accuracy: 0.9760\n",
      "Epoch 12/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0769 - accuracy: 0.9757\n",
      "Epoch 13/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0709 - accuracy: 0.9782\n",
      "Epoch 14/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0677 - accuracy: 0.9787\n",
      "Epoch 15/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0640 - accuracy: 0.9798\n",
      "Epoch 16/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0598 - accuracy: 0.9813\n",
      "Epoch 17/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0562 - accuracy: 0.9826\n",
      "Epoch 18/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0542 - accuracy: 0.9832\n",
      "Epoch 19/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0499 - accuracy: 0.9841\n",
      "Epoch 20/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0489 - accuracy: 0.9842\n",
      "Epoch 21/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0479 - accuracy: 0.9850\n",
      "Epoch 22/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0454 - accuracy: 0.9857\n",
      "Epoch 23/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0446 - accuracy: 0.9862\n",
      "Epoch 24/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0417 - accuracy: 0.9863\n",
      "Epoch 25/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0414 - accuracy: 0.9866\n",
      "Epoch 26/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0391 - accuracy: 0.9873\n",
      "Epoch 27/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0387 - accuracy: 0.9879\n",
      "Epoch 28/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0360 - accuracy: 0.9884\n",
      "Epoch 29/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0366 - accuracy: 0.9886\n",
      "Epoch 30/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0326 - accuracy: 0.9897\n",
      "Epoch 31/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0330 - accuracy: 0.9892\n",
      "Epoch 32/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0328 - accuracy: 0.9895\n",
      "Epoch 33/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0296 - accuracy: 0.9901\n",
      "Epoch 34/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0304 - accuracy: 0.9898\n",
      "Epoch 35/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0287 - accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b522caef70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, batch_size=32, epochs=35, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79569d12",
   "metadata": {},
   "source": [
    "# Running on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286870a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08790291100740433, 0.9757999777793884]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_test, y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9befdb",
   "metadata": {},
   "source": [
    "# Setting up pyramid Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f538dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((784)),\n",
    "    tf.keras.layers.Dense(128, activation='relu',kernel_initializer=initializer, name='hiddenlayer1'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu',kernel_initializer=initializer, name='hiddenlayer2'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu',kernel_initializer=initializer, name='hiddenlayer3'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(32, activation='relu',kernel_initializer=initializer, name='hiddenlayer4'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(16, activation='relu',kernel_initializer=initializer, name='hiddenlayer5'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(8, activation='relu',kernel_initializer=initializer, name='hiddenlayer6'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(4, activation='relu',kernel_initializer=initializer, name='hiddenlayer7'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(2, activation='relu',kernel_initializer=initializer, name='hiddenlayer8'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10,activation='softmax',kernel_initializer=initializer, name='outputlayer')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "018e1743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hiddenlayer1 (Dense)        (None, 128)               100480    \n",
      "                                                                 \n",
      " batch_normalization_88 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " hiddenlayer2 (Dense)        (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_89 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " hiddenlayer3 (Dense)        (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_90 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " hiddenlayer4 (Dense)        (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_91 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " hiddenlayer5 (Dense)        (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_92 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " hiddenlayer6 (Dense)        (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_93 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " hiddenlayer7 (Dense)        (None, 4)                 36        \n",
      "                                                                 \n",
      " batch_normalization_94 (Bat  (None, 4)                16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " hiddenlayer8 (Dense)        (None, 2)                 10        \n",
      "                                                                 \n",
      " batch_normalization_95 (Bat  (None, 2)                8         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 2)                 0         \n",
      "                                                                 \n",
      " outputlayer (Dense)         (None, 10)                30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 129,596\n",
      "Trainable params: 128,832\n",
      "Non-trainable params: 764\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40009d1",
   "metadata": {},
   "source": [
    "# Compiling and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21edd0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6845f41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1406 - accuracy: 0.1702\n",
      "Epoch 2/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.8812 - accuracy: 0.2324\n",
      "Epoch 3/32\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.8054 - accuracy: 0.2477\n",
      "Epoch 4/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7645 - accuracy: 0.2632\n",
      "Epoch 5/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7304 - accuracy: 0.2759\n",
      "Epoch 6/32\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.7150 - accuracy: 0.2807\n",
      "Epoch 7/32\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6943 - accuracy: 0.2901\n",
      "Epoch 8/32\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6806 - accuracy: 0.2915\n",
      "Epoch 9/32\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6634 - accuracy: 0.2962\n",
      "Epoch 10/32\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6427 - accuracy: 0.3003\n",
      "Epoch 11/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6375 - accuracy: 0.3000\n",
      "Epoch 12/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6237 - accuracy: 0.3062\n",
      "Epoch 13/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6117 - accuracy: 0.3091\n",
      "Epoch 14/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6052 - accuracy: 0.3113\n",
      "Epoch 15/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6017 - accuracy: 0.3147\n",
      "Epoch 16/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5955 - accuracy: 0.3186\n",
      "Epoch 17/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5740 - accuracy: 0.3290\n",
      "Epoch 18/32\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.5709 - accuracy: 0.3341\n",
      "Epoch 19/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5645 - accuracy: 0.3431\n",
      "Epoch 20/32\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.5680 - accuracy: 0.3396\n",
      "Epoch 21/32\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5576 - accuracy: 0.3454\n",
      "Epoch 22/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5443 - accuracy: 0.3459\n",
      "Epoch 23/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5446 - accuracy: 0.3451\n",
      "Epoch 24/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5409 - accuracy: 0.3490\n",
      "Epoch 25/32\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5446 - accuracy: 0.3477\n",
      "Epoch 26/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5451 - accuracy: 0.3530\n",
      "Epoch 27/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5400 - accuracy: 0.3535\n",
      "Epoch 28/32\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.5281 - accuracy: 0.3564\n",
      "Epoch 29/32\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5284 - accuracy: 0.3579\n",
      "Epoch 30/32\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5256 - accuracy: 0.3615\n",
      "Epoch 31/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5195 - accuracy: 0.3663\n",
      "Epoch 32/32\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5175 - accuracy: 0.3698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2849bad52e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size=32, epochs=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681fedd",
   "metadata": {},
   "source": [
    "# Running on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cbc5fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.9012 - accuracy: 0.6856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9012452363967896, 0.6855999827384949]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173c262",
   "metadata": {},
   "source": [
    "# Setting up inv pyramid neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "943298c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((784)),\n",
    "    tf.keras.layers.Dense(8, activation='relu',kernel_initializer=initializer, name='hiddenlayer1'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(8, activation='relu',kernel_initializer=initializer, name='hiddenlayer2'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(16, activation='relu',kernel_initializer=initializer, name='hiddenlayer3'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(32, activation='relu',kernel_initializer=initializer, name='hiddenlayer4'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu',kernel_initializer=initializer, name='hiddenlayer5'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu',kernel_initializer=initializer, name='hiddenlayer6'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(256, activation='relu',kernel_initializer=initializer, name='hiddenlayer7'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(512, activation='relu',kernel_initializer=initializer, name='hiddenlayer8'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10,activation='softmax',kernel_initializer=initializer, name='outputlayer')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "213d16c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hiddenlayer1 (Dense)        (None, 8)                 6280      \n",
      "                                                                 \n",
      " batch_normalization_96 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " hiddenlayer2 (Dense)        (None, 8)                 72        \n",
      "                                                                 \n",
      " batch_normalization_97 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " hiddenlayer3 (Dense)        (None, 16)                144       \n",
      "                                                                 \n",
      " batch_normalization_98 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " hiddenlayer4 (Dense)        (None, 32)                544       \n",
      "                                                                 \n",
      " batch_normalization_99 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " hiddenlayer5 (Dense)        (None, 64)                2112      \n",
      "                                                                 \n",
      " batch_normalization_100 (Ba  (None, 64)               256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " hiddenlayer6 (Dense)        (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization_101 (Ba  (None, 128)              512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " hiddenlayer7 (Dense)        (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_102 (Ba  (None, 256)              1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " hiddenlayer8 (Dense)        (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_103 (Ba  (None, 512)              2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " outputlayer (Dense)         (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 191,306\n",
      "Trainable params: 189,258\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf677f9",
   "metadata": {},
   "source": [
    "# Compiling and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d5f9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22758bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 2.0483 - accuracy: 0.2790\n",
      "Epoch 2/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5146 - accuracy: 0.4157\n",
      "Epoch 3/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3766 - accuracy: 0.4581\n",
      "Epoch 4/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2985 - accuracy: 0.4867\n",
      "Epoch 5/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2670 - accuracy: 0.5038\n",
      "Epoch 6/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2409 - accuracy: 0.5157\n",
      "Epoch 7/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2227 - accuracy: 0.5256\n",
      "Epoch 8/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2023 - accuracy: 0.5358\n",
      "Epoch 9/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1923 - accuracy: 0.5391\n",
      "Epoch 10/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1819 - accuracy: 0.5432\n",
      "Epoch 11/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.1807 - accuracy: 0.5420\n",
      "Epoch 12/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.1639 - accuracy: 0.5482\n",
      "Epoch 13/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1609 - accuracy: 0.5548\n",
      "Epoch 14/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.1556 - accuracy: 0.5611\n",
      "Epoch 15/35\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 1.1484 - accuracy: 0.5626\n",
      "Epoch 16/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1485 - accuracy: 0.5603\n",
      "Epoch 17/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1430 - accuracy: 0.5647\n",
      "Epoch 18/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1484 - accuracy: 0.5580\n",
      "Epoch 19/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.1400 - accuracy: 0.5635\n",
      "Epoch 20/35\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 1.1318 - accuracy: 0.5689\n",
      "Epoch 21/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1262 - accuracy: 0.5709\n",
      "Epoch 22/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1340 - accuracy: 0.5719\n",
      "Epoch 23/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1226 - accuracy: 0.5742\n",
      "Epoch 24/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1258 - accuracy: 0.5731\n",
      "Epoch 25/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1164 - accuracy: 0.5779\n",
      "Epoch 26/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1141 - accuracy: 0.5771\n",
      "Epoch 27/35\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1065 - accuracy: 0.5813\n",
      "Epoch 28/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.1045 - accuracy: 0.5814\n",
      "Epoch 29/35\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.0900 - accuracy: 0.5881\n",
      "Epoch 30/35\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 1.0942 - accuracy: 0.5882\n",
      "Epoch 31/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.0865 - accuracy: 0.5889\n",
      "Epoch 32/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.0970 - accuracy: 0.5901\n",
      "Epoch 33/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.0867 - accuracy: 0.5920\n",
      "Epoch 34/35\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.0752 - accuracy: 0.5966\n",
      "Epoch 35/35\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.0727 - accuracy: 0.5975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2849b88ea00>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train, y_train, batch_size=32, epochs=35, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313192bd",
   "metadata": {},
   "source": [
    "# Running the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17c67011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.6411 - accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6411056518554688, 0.8100000023841858]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_test, y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd7e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
